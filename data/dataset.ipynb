{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Processing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dùng để chính thức đổi data thô thành data set, chia thành các mini batch đưa vào tập train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib_all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Xây dựng dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Input:\n",
    "- list_img_path: danh sách đường dẫn đến các bức ảnh\n",
    "- list_anno_path: danh sách đường dẫn đến các file annotation\n",
    "- phase: pha làm việc (train/val)\n",
    "- transform: object của class Datatransform\n",
    "- anno_xml: Để convert thông tin từ file xml ra thành một list\n",
    "Output\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, list_img_path , list_anno_path, phase, DataTransform, InfoAnno ):\n",
    "        self.list_img_path = list_img_path\n",
    "        self.list_anno_path = list_anno_path\n",
    "        self.phase = phase\n",
    "        self.DataTransform = DataTransform\n",
    "        self.InfoAnno = InfoAnno\n",
    "\n",
    "    # Tim so luong buc anh ben trong dataset\n",
    "    def __len__(self):\n",
    "        return len(self.list_img_path)\n",
    "\n",
    "    # lay tung phan tu ra\n",
    "    def __getitem__(self, index):\n",
    "        img, ground_truth,height, width = self.pull_item(index)\n",
    "        return img, ground_truth # gt la mot list 5 phan tu  thong tin lien quan den bounding box, label\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        # lay thong tin ve anh\n",
    "        img_path = self.list_img_path[index]\n",
    "        img = cv2.imread(img_path) #BGR\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        #lay thong tin ve annotation\n",
    "        anno_path = self.list_anno_path[index]\n",
    "        anno_info = self.InfoAnno(anno_path, width,height)\n",
    "\n",
    "        #tien xu ly\n",
    "        img, boxes, labels = self.DataTransform(img, self.phase, anno_info[:, :4], anno_info[:, 4])\n",
    "\n",
    "        #doi thu tu cac kieu (BGR -> RGB) (height, width, channels ->channels, height, width) de phu hop voi cac ham cua pytorch\n",
    "        img = torch.from_numpy(img[:,:,(2,1,0)]).permute(2,0,1)\n",
    "\n",
    "        # gan gia tri cua bounding box, labels vao array\n",
    "        ground_truth = np.hstack((boxes, np.expand_dims(labels, axis=1)))  #stack theo chieu ngang\n",
    "        return img, ground_truth, height, width\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Chia data set thành các mini batch\n",
    "Sử dụng lại hàm DataLoader trong thư viện data ( tuy nhiên phải custom lại )\n",
    "Khác với bài toán classsification thì bài toán này không thể dùng collec_fc có sẵn được mà phải customize lại do 1 img có thể có nhiều object\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### custom lại collate_fn\n",
    "Input:\n",
    "    - mini_batch: gồm batch_size ảnh và annotation\n",
    "Output:\n",
    "    - Toàn bộ phải ở dạng tensor thì mới đưa được vào mạng ssd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def collate_fn(mini_batch):\n",
    "    annotations = []\n",
    "    imgs = []\n",
    "\n",
    "    for sample in mini_batch:\n",
    "        imgs.append(sample[0]) #sample[0] la thong so ve img\n",
    "        annotations.append(torch.FloatTensor(sample[1]))\n",
    "\n",
    "    # chuyen hinh dang imgs tu list[3, 300, 300]->tensor[batch_size, 3, 300, 300]\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    return imgs, annotations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from data.path import get_path\n",
    "from data.processing_data import  DataTransform\n",
    "from data.info_annotation import  InfoAnno"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "#annotation infomation\n",
    "classes = ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "\n",
    "#get path\n",
    "root_path = './data_set/VOCdevkit/VOC2012/'\n",
    "train_images_path, train_annotations_path, val_images_path, val_annotations_path = get_path(root_path)\n",
    "\n",
    "#prepare data transform\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "transform = DataTransform(input_size, color_mean)\n",
    "InfoAnno = InfoAnno(classes)\n",
    "train_dataset = MyDataset(train_images_path, train_annotations_path,phase=\"train\", DataTransform =transform,InfoAnno= InfoAnno)\n",
    "val_dataset = MyDataset(val_images_path, val_annotations_path,phase=\"train\", DataTransform =transform,InfoAnno= InfoAnno)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chiều dài phần tử"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phần tử đầu tiên\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), array([[0.47619048, 0.36115326, 0.58333333, 0.62670713, 4.        ],\n",
      "       [0.68849206, 0.36115326, 0.79464286, 0.58725341, 4.        ]]))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__getitem__(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "batch_size thường để là số chẵn vì khi đó nó sẽ đưa vào sử lý xong xong trong thread được"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_dataset, batch_size = 4,shuffle=True,collate_fn=collate_fn)\n",
    "\n",
    "# chuyển  thành iterator\n",
    "batch_iter = iter(train_dataloader) # luot qua tung phan tu\n",
    "images, annotations = next(batch_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chiều dài bộ dữ liệu giảm xuống 4 lần"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mỗi iter bao gồm 4 ảnh\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "print(images.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mỗi iter bao gồm 4 annotation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chieu dai annotations 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Chieu dai annotations {}\".format(len(annotations)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(annotations[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}