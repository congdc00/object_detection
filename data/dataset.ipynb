{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Processing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dùng để chính thức đổi data thô thành data set, chia thành các mini batch đưa vào tập train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib_all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Xây dựng dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Xây dựng lớp đại diện cho tập train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, list_img_path , list_anno_path, phase, DataTransform, InfoAnno ):\n",
    "        \"\"\"\n",
    "        :param list_img_path:danh sách đường dẫn đến các bức ảnh\n",
    "        :param list_anno_path:danh sách đường dẫn đến các file annotation\n",
    "        :param phase:pha làm việc (train/val)\n",
    "        :param DataTransform: transform anh\n",
    "        :param InfoAnno: Thong tin tu annotation\n",
    "        \"\"\"\n",
    "        self.list_img_path = list_img_path\n",
    "        self.list_anno_path = list_anno_path\n",
    "        self.phase = phase\n",
    "        self.DataTransform = DataTransform\n",
    "        self.InfoAnno = InfoAnno\n",
    "\n",
    "    # Tim so luong buc anh ben trong dataset\n",
    "    def __len__(self):\n",
    "        return len(self.list_img_path)\n",
    "\n",
    "    # lay tung phan tu ra\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        :param index:\n",
    "        :return: [1, num_obj]\n",
    "        \"\"\"\n",
    "        img, ground_truth,height, width = self.pull_item(index)\n",
    "        return img, ground_truth\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        \"\"\"\n",
    "        :param index: vị trí của ảnh trong path\n",
    "        :return: [1, num_obj, height, width]\n",
    "        \"\"\"\n",
    "        # lay thong tin ve anh\n",
    "        img_path = self.list_img_path[index]\n",
    "        img = cv2.imread(img_path) #BGR\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        #lay thong tin ve annotation\n",
    "        anno_path = self.list_anno_path[index]\n",
    "        anno_info = self.InfoAnno(anno_path, width,height)\n",
    "\n",
    "        #tien xu ly\n",
    "        img, boxes, labels = self.DataTransform(img, self.phase, anno_info[:, :4], anno_info[:, 4])\n",
    "\n",
    "        #doi thu tu cac kieu (BGR -> RGB) (height, width, channels ->channels, height, width) de phu hop voi cac ham cua pytorch\n",
    "        img = torch.from_numpy(img[:,:,(2,1,0)]).permute(2,0,1)\n",
    "\n",
    "        # gan gia tri cua bounding box, labels vao array\n",
    "        ground_truth = np.hstack((boxes, np.expand_dims(labels, axis=1)))  #stack theo chieu ngang\n",
    "        return img, ground_truth, height, width\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Dataloader\n",
    "Dùng để load một lượng batch size từ MyDataset\n",
    "Sử dụng lại hàm DataLoader trong thư viện data\n",
    "Khác với bài toán classsification thì bài toán này không thể dùng collec_fc có sẵn được mà phải customize lại do 1 img có thể có nhiều object\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def collate_fn(batch_img):\n",
    "    \"\"\"\n",
    "    :param batch_img:gồm batch_size ảnh và annotation\n",
    "    :return: batch_size, batch_size\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    imgs = []\n",
    "\n",
    "    for sample in batch_img:\n",
    "        imgs.append(sample[0]) #sample[0] la thong so ve img\n",
    "        annotations.append(torch.FloatTensor(sample[1]))\n",
    "\n",
    "    # chuyen hinh dang imgs tu list[3, 300, 300]->tensor[batch_size, 3, 300, 300]\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    return imgs, annotations #Toàn bộ phải ở dạng tensor thì mới đưa được vào mạng ssd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from data.path import get_path\n",
    "from data.processing_data import  DataTransform\n",
    "from data.info_annotation import  InfoAnno"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#annotation infomation\n",
    "classes = ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "\n",
    "#get path\n",
    "root_path = './data_set/VOCdevkit/VOC2012/'\n",
    "train_images_path, train_annotations_path, val_images_path, val_annotations_path = get_path(root_path)\n",
    "\n",
    "#prepare data transform\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "transform = DataTransform(input_size, color_mean)\n",
    "InfoAnno = InfoAnno(classes)\n",
    "train_dataset = MyDataset(train_images_path, train_annotations_path,phase=\"train\", DataTransform =transform,InfoAnno= InfoAnno)\n",
    "val_dataset = MyDataset(val_images_path, val_annotations_path,phase=\"train\", DataTransform =transform,InfoAnno= InfoAnno)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chiều dài phần tử"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phần tử đầu tiên\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ -18.1495,  -18.8845,  -18.0329,  ...,   44.7338,   46.1155,\n",
      "            46.8505],\n",
      "         [ -17.2395,  -17.9745,  -17.6310,  ...,   47.9719,   48.8455,\n",
      "            49.5805],\n",
      "         [ -16.2995,  -15.7850,  -14.5666,  ...,   46.2167,   47.2412,\n",
      "            49.8505],\n",
      "         ...,\n",
      "         [ -64.0495,  -80.7708,  -91.2941,  ...,  -55.4179,  -53.8035,\n",
      "           -56.4495],\n",
      "         [ -87.5895,  -93.3519,  -93.8550,  ...,  -38.6349,  -36.1791,\n",
      "           -41.0595],\n",
      "         [-102.1495,  -91.8595,  -87.5912,  ...,  -38.8245,  -37.9445,\n",
      "           -40.1495]],\n",
      "\n",
      "        [[ -39.1495,  -39.8845,  -38.4745,  ...,   41.7338,   43.1155,\n",
      "            43.8505],\n",
      "         [ -38.2395,  -38.9745,  -38.0726,  ...,   44.9719,   45.8455,\n",
      "            46.5805],\n",
      "         [ -37.2995,  -36.7850,  -35.0083,  ...,   43.2167,   44.2412,\n",
      "            46.8505],\n",
      "         ...,\n",
      "         [ -58.7995,  -78.1300,  -90.2362,  ...,  -35.7933,  -34.6535,\n",
      "           -37.2995],\n",
      "         [ -86.9495,  -93.6454,  -95.4509,  ...,  -18.6852,  -16.1791,\n",
      "           -21.0595],\n",
      "         [-105.1495,  -97.7995,  -94.0329,  ...,  -19.3829,  -17.9445,\n",
      "           -20.1495]],\n",
      "\n",
      "        [[  19.8505,   20.5855,   23.0838,  ...,   62.7338,   64.1155,\n",
      "            64.8505],\n",
      "         [  20.7605,   21.4955,   23.4857,  ...,   65.9719,   66.8455,\n",
      "            67.5805],\n",
      "         [  21.7005,   23.6850,   26.5501,  ...,   64.2167,   65.2412,\n",
      "            67.8505],\n",
      "         ...,\n",
      "         [ -18.4495,  -32.8555,  -40.9529,  ...,  -40.5441,  -40.3535,\n",
      "           -42.9995],\n",
      "         [ -38.3195,  -41.2742,  -39.5981,  ...,  -22.7857,  -20.1791,\n",
      "           -25.0595],\n",
      "         [ -50.1495,  -38.3895,  -31.9162,  ...,  -24.4995,  -21.9445,\n",
      "           -24.1495]]]), array([[0.18218623, 0.        , 0.61538462, 0.5070922 , 4.        ]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DINH CHI CONG\\OneDrive - Hanoi University of Science and Technology\\Study\\University\\Machine Learning & Data Mining\\Object_detection\\sourc_code\\utils\\augmentations.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__getitem__(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "batch_size thường để là số chẵn vì khi đó nó sẽ đưa vào sử lý xong xong trong thread được"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_dataset, batch_size = 4,shuffle=True,collate_fn=collate_fn)\n",
    "\n",
    "# chuyển  thành iterator\n",
    "batch_iter = iter(train_dataloader) # luot qua tung phan tu\n",
    "images, annotations = next(batch_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chiều dài bộ dữ liệu giảm xuống 4 lần"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mỗi iter bao gồm 4 ảnh\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "print(images.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mỗi iter bao gồm 4 annotation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chieu dai annotations 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Chieu dai annotations {}\".format(len(annotations)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(annotations[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}