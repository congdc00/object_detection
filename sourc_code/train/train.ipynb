{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Data loader: VOC2012\n",
    "- Network: SSD300\n",
    "- Loss: MultiboxLoss\n",
    "- Optimizer\n",
    "- Tranning, validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib_all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train nhanh hơn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import 1 số hàm đã tạo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from data.path import get_path\n",
    "from data.dataset import MyDataset, collate_fn\n",
    "from data.processing_data import DataTransform\n",
    "from data.info_annotation import InfoAnno\n",
    "from sourc_code.model.model import SSD\n",
    "from sourc_code.model.multibox_loss import MultiBoxLoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I. Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tạo path list trainning và validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "root_path ='../../data/data_set/VOCdevkit/VOC2012'\n",
    "train_images_path, train_annotations_path, val_images_path, val_annotations_path = get_path(root_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "classes = ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "train_dataset = MyDataset(train_images_path,train_annotations_path, phase = \"train\", DataTransform = DataTransform(input_size, color_mean), InfoAnno = InfoAnno(classes) )\n",
    "val_dataset = MyDataset(val_images_path,val_images_path, phase = \"val\", DataTransform = DataTransform(input_size, color_mean), InfoAnno = InfoAnno(classes) )\n",
    "\n",
    "# tao data loader\n",
    "batch_size = 2\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "dataloader_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"num_classes\": 21,\n",
    "    \"input_size\": 300,\n",
    "    \"aspect_num\": [4, 6, 6, 6, 4, 4], #so bbox/ pixel  trong so cho cac sorce tu 1 -> 6\n",
    "    \"feature_maps\": [38, 19, 10, 5, 3, 1],\n",
    "    \"steps\": [8, 16, 32, 64, 100, 300], # size cua pixel\n",
    "    \"min_size\": [30, 60, 111, 162, 213, 264],  #size cua default box\n",
    "    \"max_size\": [60, 111, 162, 213, 264, 315], #size cua default box\n",
    "    \"aspect_ratio\":[[2],[2,3],[2,3],[2,3],[2],[2]]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "net = SSD(phase = \"train\", cfg = configs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "vgg_weigth = torch.load(\"../../data/download/vgg16_reducedfc.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.vgg.load_state_dict(vgg_weigth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hàm số để load thông số khởi tạo cho từng layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    #neu model la instance nn.Conv2d\n",
    "    if isinstance(model, nn.Conv2d):\n",
    "        # sinh ra cac gia tri da duoc chuan hoa de khoi tao model\n",
    "        nn.init.kaiming_normal_(model.weight.data)\n",
    "        # neu model co bias\n",
    "        if model.bias is not None:\n",
    "            nn.init.constant_(model.bias, 0.0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Khởi tạo network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "ModuleList(\n  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Khởi tạo loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "criterion = MultiBoxLoss(jaccard_threshold = 0.5, scale_ne_po = 3, device = device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# V. Trainning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epochs):\n",
    "    net.to(device)\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "    for epoch in range(num_epochs+1):\n",
    "        # moi epochs mat bao nhieu thoi gian\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"---\"*20)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                # goi ham train tu class me (inabale cac tenso de ma luu duoc gradian khi trainning)\n",
    "                net.train()\n",
    "                print(\"(Training)\")\n",
    "            else:\n",
    "                if (epoch+1) % 10 == 0:\n",
    "                    net.eval()\n",
    "                    print(\"---\"*10)\n",
    "                    print(\"(Validation)\")\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            for images, targets in dataloader_dict[phase]:\n",
    "                # move to GPU\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # init optimizer: dua gradian ve 0 sau moi lan load anh\n",
    "                optimizer.zero_grad()\n",
    "                #forward: dua anh vao trong mang\n",
    "                with torch.set_grad_enabled(phase==\"train\"): #enabled cac tham so de chua dao ham\n",
    "                    output = net(images)\n",
    "\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # calculate gradient\n",
    "                        # gradient co kha nang cao -> cap nhap parameter dan den bat on dinh -> phai cat no di\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0) # gia tri parameter khong lon hon 2.0\n",
    "                        optimizer.step() # update parameters\n",
    "                        \n",
    "                        if (iteration % 10) == 0:\n",
    "                            t_iter_end = time.time()\n",
    "                            duration = t_iter_end - t_iter_start\n",
    "                            print(\"Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_end = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {} || epoch_train_loss: {:.4f} || Epoch_val_loss: {:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print(\"Duration: {:.4f} sec\".format(t_epoch_end - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\": epoch+1, \"train_loss\": epoch_train_loss, \"val_loss\": epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"./data/ssd_logs.csv\")\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), \"./data/weights/ssd300_\" + str(epoch+1) + \".pth\")\n",
    "num_epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 1/100\n",
      "------------------------------------------------------------\n",
      "(Training)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DINH CHI CONG\\OneDrive - Hanoi University of Science and Technology\\Study\\University\\Machine Learning & Data Mining\\Object_detection\\sourc_code\\utils\\augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\DINHCH~1\\AppData\\Local\\Temp/ipykernel_15376/545327734.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataloader_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\Users\\DINHCH~1\\AppData\\Local\\Temp/ipykernel_15376/1779468051.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(net, dataloader_dict, criterion, optimizer, num_epochs)\u001B[0m\n\u001B[0;32m     37\u001B[0m                     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 39\u001B[1;33m                     \u001B[0mloss_l\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_c\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     40\u001B[0m                     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_l\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mloss_c\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(net, dataloader_dict, criterion, optimizer, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}