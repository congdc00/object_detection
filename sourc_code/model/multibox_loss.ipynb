{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sourc_code.utils.box_utils as box_utils\n",
    "from lib_all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiBoxLoss(nn.Module):\n",
    "    def __init__(self, jaccard_threshold = 0.5, scale_ne_po = 3, device = \"cpu\"):\n",
    "        \"\"\"\n",
    "        :param jaccard_threshold: nguong jaccard, lon hon thi la positive\n",
    "        :param scale_ne_po: ti le negative/positive\n",
    "        :param device: train tren thiet bi nao\n",
    "        \"\"\"\n",
    "        super(MultiBoxLoss, self).__init__() # khoi tao Module va ke thua\n",
    "        self.jaccard_threshold = jaccard_threshold\n",
    "        self.scale_ne_po = scale_ne_po\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        :param prediction: du doan\n",
    "        :param target: label\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        loc_data, conf_data, dbox_list = predictions\n",
    "\n",
    "        #loc_data = (batch_size, num_dbox, 4)\n",
    "        batch_size = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data.size(2)\n",
    "\n",
    "        # Bien doi thong tin annotation thanh label can hoc bang cach tao ra 2 tensor rong\n",
    "        conf_t_label = torch.LongTensor(batch_size, num_dbox).to(self.device) # chuyen ve dang long de sau nay dua vao F.\n",
    "        loc_t= torch.Tensor(batch_size, num_dbox, 4)\n",
    "\n",
    "        for index in range(batch_size):\n",
    "            truths_box = targets[index][:, :-1].to(self.device) #(object, location)\n",
    "            labels = targets[index][:, -1].to(self.device)\n",
    "\n",
    "            dbox = dbox_list.to(self.device)\n",
    "            variances = [0.1, 0.2] # he so de bien doi tu dbox sang bbox\n",
    "            box_utils.match(self.jaccard_threshold, truths_box, dbox, variances, labels, loc_t, conf_t_label, index)\n",
    "\n",
    "        #SmoothL1Loss\n",
    "        pos_mask = conf_t_label > 0 # khong lay background, conf_t_label [num_img, dfbox]\n",
    "        #cac tensor khi tinh toan can cung hinh dang voi nhau\n",
    "        pos_index = pos_mask.unsqueeze(pos_mask.dim()).expand_as(loc_data)\n",
    "\n",
    "        #positive dbox, loc_data\n",
    "        loc_p = loc_data[pos_index].view(-1,4)\n",
    "\n",
    "        # nhan offset\n",
    "        loc_t = loc_t[pos_index].view(-1,4)\n",
    "\n",
    "        loss_loc =  F.smooth_l1_loss(loc_p, loc_t, reduction=\"sum\")\n",
    "\n",
    "        #loss_conf\n",
    "        #Cross_entropy\n",
    "        batch_conf = conf_data.view(-1, num_classes) #(num_batch*num_dbox, num_classes)\n",
    "        loss_conf = F.cross_entropy(batch_conf, conf_t_label, reduction=\"none\")\n",
    "\n",
    "        #hard negative mining\n",
    "        num_pos = pos_mask.long().sum(1, keepdim = True) # tinh so >=1 theo hang ngang cua tung anh va giu cac chieu con lai\n",
    "        loss_conf = loss_conf.view(batch_size, - 1 ) # dua ve dang nay sau nay de tinh loss\n",
    "\n",
    "        # sap xep\n",
    "        _, index_loss = loss_conf.sort(1, descending = True) #sap xep giam dan\n",
    "        # thu hang cua cac index theo do lon, chi ra duoc index nay lon thu bao nhieu\n",
    "        _,index_rank = loss_conf.sort(1)\n",
    "\n",
    "        num_neg = torch.clamp(num_pos*self.scale_ne_po, max=num_dbox)\n",
    "        neg_mask = index_rank < (num_neg).expand_as(index_rank) # dam bao tensor nhan duoc cua dinh dang cua index_rank\n",
    "\n",
    "        #(num_batch, 8732) -> (num_batch, 8732, 21)\n",
    "        pos_idx_mask = pos_mask.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx_mask = neg_mask.unsqueeze(2).expand_as(conf_data)\n",
    "\n",
    "        # mang du doan ra\n",
    "        conf_t_pre = conf_data[(pos_idx_mask+neg_idx_mask).gt(0)].view(-1, num_classes) #(num_batch*8732, 21)\n",
    "        # nhan cua minh\n",
    "        conf_t_label_ = conf_t_label[(pos_mask+neg_mask).gt(0)]\n",
    "\n",
    "\n",
    "        loss_conf = F.cross_entropy(conf_t_pre, conf_t_label_, reduction=\"sum\")\n",
    "\n",
    "        # total loss = loss_loc + loss_conf\n",
    "        N = num_pos.sum() # negative khong tinh\n",
    "        loss_loc = loss_loc/N\n",
    "        loss_conf = loss_conf/N\n",
    "\n",
    "        return loss_loc, loss_conf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 3, 1],\n",
      "        [3, 2, 0, 1]])\n",
      "tensor([[0, 3, 1, 2],\n",
      "        [2, 3, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "loss = torch.Tensor([[5,2,4,3],[3,1,5,6]])\n",
    "_, index = loss.sort(1,descending = True)\n",
    "_,index_final = index.sort(1)\n",
    "print(index)\n",
    "print(index_final)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}