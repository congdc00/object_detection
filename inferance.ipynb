{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from lib_all import *\n",
    "from ui import result\n",
    "import nbimporter\n",
    "from sourc_code.model.model import SSD\n",
    "from data.processing_data import DataTransform\n",
    "\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\",  \"boat\", \"bottle\",\n",
    "           \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "cfg = {\n",
    "    \"num_classes\": 21, #VOC data include 20 class + 1 background class\n",
    "    \"input_size\": 300, #SSD300\n",
    "    \"bbox_aspect_num\": [4, 6, 6, 6, 4, 4], # Tỷ lệ khung hình cho source1->source6`\n",
    "    \"feature_maps\": [38, 19, 10, 5, 3, 1],\n",
    "    \"steps\": [8, 16, 32, 64, 100, 300], # Size of default box\n",
    "    \"min_size\": [30, 60, 111, 162, 213, 264], # Size of default box\n",
    "    \"max_size\": [60, 111, 162, 213, 264, 315], # Size of default box\n",
    "    \"aspect_ratios\": [[2], [2,3], [2,3], [2,3], [2], [2]]\n",
    "}\n",
    "\n",
    "net = SSD(phase=\"inference\", cfg=cfg)\n",
    "net_weights = torch.load(\"./data/weights/ssd300/ssd300_100.pth\", map_location={\"cuda:0\":\"cpu\"})\n",
    "net.load_state_dict(net_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "show ra cac gia tri du doan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def predict(img_file_path):\n",
    "    \"\"\"\n",
    "    :param img_file_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_file_path)\n",
    "\n",
    "    color_mean = (104, 117, 123)\n",
    "    input_size = 300\n",
    "    transform = DataTransform(input_size, color_mean)\n",
    "\n",
    "    phase = \"val\"\n",
    "    img_tranformed, boxes, labels = transform(img, phase, \"\", \"\")\n",
    "    img_tensor = torch.from_numpy(img_tranformed[:,:,(2,1,0)]).permute(2,0,1)\n",
    "\n",
    "    net.eval() # chuyen ve dang validation\n",
    "    input = img_tensor.unsqueeze(0) #(1, 3, 300, 300)\n",
    "    output = net(input)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    colors = [(255,0,0), (0,255,0), (0,0,255)]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    detections = output.data #(1, 21, 200, 5) 5: score, cx, cy, w, h\n",
    "    scale = torch.Tensor(img.shape[1::-1]).repeat(2)\n",
    "\n",
    "    for i in range(detections.size(1)):\n",
    "        j = 0\n",
    "        while detections[0, i, j, 0] >= 0.6:\n",
    "            score = detections[0, i, j, 0]\n",
    "            pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n",
    "            cv2.rectangle(img,\n",
    "                          (int(pt[0]), int(pt[1])),\n",
    "                          (int(pt[2]), int(pt[3])),\n",
    "                          colors[i%3], 2\n",
    "                          )\n",
    "            display_text = \"%s: %.2f\"%(classes[i-1], score)\n",
    "            cv2.putText(img, display_text, (int(pt[0]), int(pt[1])),\n",
    "                        font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            j += 1\n",
    "    return img\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_file_path = \"data/database/ask.jpg\"\n",
    "img = predict(img_file_path)\n",
    "cv2.imwrite(\"data/database/result.jpg\", img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}